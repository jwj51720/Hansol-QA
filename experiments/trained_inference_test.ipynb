{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer,BitsAndBytesConfig, pipeline\n",
    "import torch\n",
    "import pandas as pd\n",
    "from peft import (\n",
    "    AutoPeftModelForCausalLM,\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    PeftConfig,\n",
    "    PeftModel\n",
    ")\n",
    "import re\n",
    "\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- peft 학습한 것 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model_id = \"../result/LDCC-SOLAR-10.7B_2024-03-06_01-30-41/best\"\n",
    "load_tokenizer_name = \"../result/LDCC-SOLAR-10.7B_2024-03-06_01-30-41\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "                load_in_4bit=True,\n",
    "                bnb_4bit_use_double_quant=False,\n",
    "                bnb_4bit_quant_type=\"nf4\",\n",
    "                bnb_4bit_compute_dtype=\"float16\",\n",
    "            )\n",
    "\n",
    "models = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, revision=\"v1.1\", quantization_config=bnb_config)\n",
    "models = PeftModel.from_pretrained(models, peft_model_id)\n",
    "models = models.merge_and_unload() # 7481 -> 8047\n",
    "\n",
    "tokenizers = AutoTokenizer.from_pretrained(load_tokenizer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 일반 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"LDCC/LDCC-SOLAR-10.7B\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=False,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=\"float16\",\n",
    "        )\n",
    "lora_config = LoraConfig(\n",
    "                lora_alpha=32,\n",
    "                lora_dropout=0.1,\n",
    "                r=8,\n",
    "                bias=\"none\",\n",
    "                task_type=\"CAUSAL_LM\",\n",
    "            )\n",
    "models = AutoModelForCausalLM.from_pretrained(model_id, revision=\"v1.1\", quantization_config=bnb_config)\n",
    "models.config.use_cache = False\n",
    "models.config.pretraining_tp = 1\n",
    "models.enable_input_require_grads()\n",
    "model = get_peft_model(models, lora_config)\n",
    "\n",
    "# tokenizers = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test_split_category.csv\")\n",
    "\n",
    "print(tokenizers.pad_token)\n",
    "print(tokenizers.eos_token)\n",
    "\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_info = {\n",
    "    \"건축구조\": \"여러 가지 건축 재료를 이용하여 건축물을 형성하는 일 또는 그 건축물에 관한 질문입니다.\",\n",
    "    \"마감재\": \"건물의 겉면을 마감하는 데 쓰는 재료 및 외부의 여러 가지 영향으로부터 건물을 보호하는 것에 관한 질문입니다.\",\n",
    "    \"마감하자\": \"건물의 겉면을 마감하는 데 쓰는 재료 및 건물 보호 재료에 생기는 문제에 관한 질문입니다.\",\n",
    "    \"시공\": \"공사를 시행하면서 사용하는 재료나 방법에 관한 질문입니다.\",\n",
    "    \"인테리어\": \"실내를 장식하는 일이나 실내 장식용품에 관한 질문입니다.\",\n",
    "    \"타 마감하자\": \"표면에 물방울이 맺혀 문제가 생기는 결로 등 생활하면서 생기는 문제에 관한 질문입니다.\",\n",
    "    \"기타\": \"집 내부와 생활 기준 및 건축의 포괄적인 분야에 관한 질문입니다.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 5\n",
    "\n",
    "input_text = test.loc[id, '질문']\n",
    "category = test.loc[id, 'category']\n",
    "\n",
    "with open(\"../template/ldcc.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "answer_start_index = content.find(\"<answer>\")\n",
    "content = content[:answer_start_index]\n",
    "content = content.replace(\"<question>\", input_text.strip().replace('\"', \"\"))\n",
    "content = content.replace(\"<category>\", category_info.get(category))\n",
    "\n",
    "input_ids = tokenizers.encode(\n",
    "            content, padding=False, max_length=256, return_tensors=\"pt\", add_special_tokens=False\n",
    "        )\n",
    "print(content, \"\\n--------------\\n\")\n",
    "print(content.replace(\"\\n\", \"\\\\n\"), \"\\n--------------\\n\")\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_sequences = models.generate(\n",
    "        input_ids=input_ids.to(\"cuda\"),\n",
    "        max_length=512,\n",
    "        temperature=0.2,\n",
    "        top_k=50,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.2,\n",
    "        do_sample=True,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "\n",
    "print(tokenizers.decode(output_sequences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = \"철골구조의 경우, 단열 효과를 높이기 위해 벽체와 천장간의 거리를 늘리고 두께를 증대하는 것이 좋습니다. 또한 외단열 시스템을 도입하여 빌딩 겉면으로의 열전달을 차단하는 방법이 유용합니다. 이를 통해 단열 효과를 향상시키고 건물 내부의 온도를 안정화할 수 있습니다.<|im_end|>\"\n",
    "nn = \"철골구조의 경우, 단열 효과를 높이기 위해 벽체와 천장 등의 내부 마감재를 단열재로 채워주는 것이 일반적인 방식입니다. 또한 외피 단열막을 설치하여 빌딩 표면 temperature to zero'를 유지하는 것도 중요합니다. 이렇게 함으로써 단열재가 건물 내부의 온도를 안정화시키고, 열이 밖으로 누출되는 것을 방지할 수 있습니다.<|im_end|>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "model = SentenceTransformer(\"distiluse-base-multilingual-cased-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = model.encode([\"방청 페인트는 다양한 종류로 분류됩니다 . 그 중에서 가장 흔 히 사용되는 것은 광 명단 페인 트, 방청산화철 페인 트, 알루미늄 페인 트, 역청질 페인 트, 워시 프라이머 , 크롬 산아연 페인 트 등이 있습니다 . 이러한 다양한 종류 의 방청 페인트가 각자의 특성과 용도에 맞 게 사용됩니다 .\"])\n",
    "t = model.encode([\"방청 페인트는 다양한 종류로 분류됩니다. 그 중에서 가장 흔히 사용되는 것은 광명단 페인트, 방청산화철 페인트, 알루미늄 페인트, 역청질 페인트, 워시 프라이머, 크롬 산아연 페인트 등이 있습니다. 이러한 다양한 종류의 방청 페인트가 각자의 특성과 용도에 맞게 사용됩니다.\"])\n",
    "cosine_similarity(k, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start token이 잘못되어 보정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(CFG, preds):\n",
    "    model = SentenceTransformer(\"distiluse-base-multilingual-cased-v1\")\n",
    "    nl = pd.read_csv(f\"../{CFG['DATA_PATH']}/{CFG['TEST_DATA']}\")\n",
    "    submit = pd.read_csv(f\"../{CFG['DATA_PATH']}/{CFG['SUBMISSION_DATA']}\")\n",
    "    submission_name = \"DataVortexS-10.7B-dpo-v1.11_2024-03-04_02-11-13\"\n",
    "    nl[\"답변\"] = preds\n",
    "    nl.to_csv(f'../{CFG[\"SAVE_PATH\"]}/{submission_name}/NL_{submission_name}.csv', index=False)\n",
    "    if len(nl) != len(submit):\n",
    "        nl = (\n",
    "            nl.groupby(\"id\")[\"답변\"]\n",
    "            .apply(lambda x: \" \".join(x.astype(str)))\n",
    "            .reset_index()\n",
    "        )\n",
    "        preds = nl[\"답변\"]\n",
    "        nl.to_csv(f'../{CFG[\"SAVE_PATH\"]}/{submission_name}/NL_merge_{submission_name}.csv', index=False)\n",
    "    pred_embeddings = model.encode(preds)\n",
    "    print(\"Shape of Prediction Embeddings: \", pred_embeddings.shape)\n",
    "    submit.iloc[:, 1:] = pred_embeddings\n",
    "    submit.to_csv(f'../{CFG[\"SAVE_PATH\"]}/{submission_name}/{submission_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../config/datavortex_0304.json', 'r', encoding='utf-8') as file:\n",
    "    CFG = json.load(file)\n",
    "    \n",
    "infer_csv = pd.read_csv(\"../result/NL_DataVortexS-10.7B-dpo-v1.11_2024-03-04_02-11-13.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "start_token = \"### Assistant: \"\n",
    "for full_text in infer_csv['답변']:\n",
    "    answer_start = full_text.find(start_token) + len(start_token)\n",
    "    answer_only = full_text[answer_start:].strip()\n",
    "    answer_only = answer_only.replace(\"\\n\", \"\")\n",
    "    answer_only = re.sub(r'\\s+', ' ', answer_only)\n",
    "    answer_only = answer_only.replace(\"<|im_end|>\", \"\")\n",
    "    answer_only = answer_only.replace(\"</s>\", \"\")\n",
    "    preds.append(answer_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission(CFG, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
